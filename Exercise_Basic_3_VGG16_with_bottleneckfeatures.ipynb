{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained ConvNet with for the Dogs vs Cats dataset\n",
    "The dataset can be downloaded at [Kaggle](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
    "We use the pre-trained ConvNet to achieve the bottleneck features (the features generated from block5_pool layer, which will be pass through the following fully-connected layers)\n",
    "> Bottleneck features are generated from a multi-layer perceptron in which one of the internal layers has a small number of hidden units, relative to the size of the other layers according to the following paper. [Reference](https://www.microsoft.com/en-us/research/publication/improved-bottleneck-features-using-pretrained-deep-neural-networks/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F153642%2Fbottleneck-interspeech2011-pub.pdf)\n",
    ">\n",
    "\n",
    "The following codes are modified based on [Reference](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) created by Francois Chollet.\n",
    "\n",
    "**Remark** Although Keras and tf.keras in most cases are compatible, but sometimes you will have unexpected errors. Most of the suggestions on the website are for Keras, some of them will not work for tf.keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.6748 - acc: 0.7575 - val_loss: 0.2816 - val_acc: 0.8825\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.3732 - acc: 0.8525 - val_loss: 0.4034 - val_acc: 0.8450\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 0s 207us/step - loss: 0.3359 - acc: 0.8715 - val_loss: 0.3509 - val_acc: 0.8488\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 0s 215us/step - loss: 0.2785 - acc: 0.8890 - val_loss: 0.2806 - val_acc: 0.8912\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 0s 202us/step - loss: 0.2472 - acc: 0.9110 - val_loss: 0.2743 - val_acc: 0.9012\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 0s 203us/step - loss: 0.2174 - acc: 0.9165 - val_loss: 0.3375 - val_acc: 0.8925\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 0s 205us/step - loss: 0.2036 - acc: 0.9345 - val_loss: 0.3694 - val_acc: 0.8912\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 0s 202us/step - loss: 0.1613 - acc: 0.9370 - val_loss: 0.8128 - val_acc: 0.8063\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 0s 225us/step - loss: 0.1521 - acc: 0.9420 - val_loss: 0.3589 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 0s 221us/step - loss: 0.1381 - acc: 0.9505 - val_loss: 0.4073 - val_acc: 0.8962\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.1218 - acc: 0.9510 - val_loss: 0.4244 - val_acc: 0.9012\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 0s 224us/step - loss: 0.1275 - acc: 0.9510 - val_loss: 0.7064 - val_acc: 0.8562\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 0s 199us/step - loss: 0.0997 - acc: 0.9660 - val_loss: 0.4387 - val_acc: 0.8875\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 0s 201us/step - loss: 0.0880 - acc: 0.9690 - val_loss: 0.4436 - val_acc: 0.9012\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 0s 201us/step - loss: 0.1001 - acc: 0.9660 - val_loss: 0.4931 - val_acc: 0.9062\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 0s 208us/step - loss: 0.0784 - acc: 0.9695 - val_loss: 0.5117 - val_acc: 0.9038\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 0s 214us/step - loss: 0.0593 - acc: 0.9780 - val_loss: 0.5704 - val_acc: 0.9038\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 0s 202us/step - loss: 0.0567 - acc: 0.9795 - val_loss: 0.5608 - val_acc: 0.9038\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 0s 203us/step - loss: 0.0591 - acc: 0.9780 - val_loss: 0.5992 - val_acc: 0.9075\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.0497 - acc: 0.9830 - val_loss: 0.6228 - val_acc: 0.9025\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 0s 219us/step - loss: 0.0675 - acc: 0.9815 - val_loss: 0.6630 - val_acc: 0.8950\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 0s 207us/step - loss: 0.0459 - acc: 0.9825 - val_loss: 0.9364 - val_acc: 0.8738\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 0s 205us/step - loss: 0.0643 - acc: 0.9860 - val_loss: 0.7035 - val_acc: 0.8950\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.0332 - acc: 0.9885 - val_loss: 0.6924 - val_acc: 0.9062\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 0s 201us/step - loss: 0.0374 - acc: 0.9890 - val_loss: 0.7314 - val_acc: 0.8962\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.0338 - acc: 0.9895 - val_loss: 0.9732 - val_acc: 0.8675\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 0s 206us/step - loss: 0.0307 - acc: 0.9875 - val_loss: 0.7097 - val_acc: 0.9025\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.0271 - acc: 0.9920 - val_loss: 0.7446 - val_acc: 0.8975\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 0s 230us/step - loss: 0.0241 - acc: 0.9910 - val_loss: 0.7671 - val_acc: 0.8962\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 0s 211us/step - loss: 0.0265 - acc: 0.9895 - val_loss: 0.8341 - val_acc: 0.8938\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 0s 212us/step - loss: 0.0158 - acc: 0.9940 - val_loss: 1.0317 - val_acc: 0.8775\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 0s 200us/step - loss: 0.0367 - acc: 0.9905 - val_loss: 0.8587 - val_acc: 0.8962\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 0s 206us/step - loss: 0.0255 - acc: 0.9895 - val_loss: 0.8079 - val_acc: 0.9012\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 0s 225us/step - loss: 0.0218 - acc: 0.9925 - val_loss: 0.7862 - val_acc: 0.8925\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 0s 205us/step - loss: 0.0224 - acc: 0.9925 - val_loss: 0.8020 - val_acc: 0.9012\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 0s 204us/step - loss: 0.0248 - acc: 0.9920 - val_loss: 0.8543 - val_acc: 0.8950\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 0s 222us/step - loss: 0.0147 - acc: 0.9965 - val_loss: 0.9737 - val_acc: 0.8938\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 0s 205us/step - loss: 0.0170 - acc: 0.9945 - val_loss: 0.8376 - val_acc: 0.9012\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 0s 209us/step - loss: 0.0179 - acc: 0.9970 - val_loss: 0.9366 - val_acc: 0.9025\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 0s 202us/step - loss: 0.0245 - acc: 0.9915 - val_loss: 0.8875 - val_acc: 0.8962\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 0s 203us/step - loss: 0.0077 - acc: 0.9970 - val_loss: 0.9181 - val_acc: 0.9012\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 0s 200us/step - loss: 0.0249 - acc: 0.9930 - val_loss: 0.9082 - val_acc: 0.9000\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 0s 201us/step - loss: 0.0175 - acc: 0.9960 - val_loss: 0.9268 - val_acc: 0.8988\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 0s 209us/step - loss: 0.0028 - acc: 0.9990 - val_loss: 1.0540 - val_acc: 0.8912\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 0s 215us/step - loss: 0.0401 - acc: 0.9915 - val_loss: 0.9594 - val_acc: 0.9025\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 0s 205us/step - loss: 0.0152 - acc: 0.9945 - val_loss: 0.8908 - val_acc: 0.9000\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 0s 205us/step - loss: 0.0149 - acc: 0.9955 - val_loss: 1.0005 - val_acc: 0.8850\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 0s 207us/step - loss: 0.0115 - acc: 0.9980 - val_loss: 0.9576 - val_acc: 0.8950\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 0s 200us/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.9138 - val_acc: 0.8975\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 0s 201us/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.9669 - val_acc: 0.8888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/dogs-vs-cats-small/train'\n",
    "validation_data_dir = 'data/dogs-vs-cats-small/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # load the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    \n",
    "    # pre-processing pipeline\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    # generate the bottleneck train features and save them as the new training data\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "   \n",
    "    # generate the bottleneck validation features and save them as the new validation data\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    # load the new training and validation data\n",
    "    train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "    \n",
    "    # build a fully connect network\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "\n",
    "save_bottleneck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before using it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ad8bc799dd8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0msave_bottleneck_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mtrain_top_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ad8bc799dd8d>\u001b[0m in \u001b[0;36msave_bottleneck_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         shuffle=False)\n\u001b[1;32m     31\u001b[0m     bottleneck_features_train = model.predict_generator(\n\u001b[0;32m---> 32\u001b[0;31m         generator, nb_train_samples // batch_size)\n\u001b[0m\u001b[1;32m     33\u001b[0m     np.save(open('bottleneck_features_train.npy', 'wb'),\n\u001b[1;32m     34\u001b[0m             bottleneck_features_train)\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2298\u001b[0;31m         verbose=verbose)\n\u001b[0m\u001b[1;32m   2299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_callback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;34m\"\"\"See docstring for `Model.predict_generator`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m   \u001b[0msteps_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_test_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You must compile your model before using it.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       inputs = (self._feed_inputs +\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before using it."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/dogs-vs-cats-small/train'\n",
    "validation_data_dir = 'data/dogs-vs-cats-small/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "\n",
    "save_bottleneck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexpected error, compile the model before using it even for the pre-trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
